{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression non-numeric feature combined with numeric features\n",
    "\n",
    "This notebook contains code to train and evaluate a linear regression model using a single non-numeric feature, two numeric features and numeric label.\n",
    "There is a good post on [Stack overflow](https://stackoverflow.com/questions/34007308/linear-regression-analysis-with-string-categorical-features-variables) on the topic of string and categorical values as features\n",
    "\n",
    "One-hot encoding will be used to convert the string feature into numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required python libraries\n",
    "- **pandas** contains the dataframe object and a number of useful methods for manipulating and querying data contained in a dataframe\n",
    "- **numpy** contains a number of useful mathematical operations including some that are helpful when evaluating accuracy of trained models\n",
    "- **Scikitlearn train_test_split** splits data into training and test sets\n",
    "- **scikitlearn LinearRegression** used to train a linear regression model\n",
    "- **scikitlearn metrics** used to calculate metrics such as Mean Squared Error, helpful when evaluating accuracy of trained models\n",
    "- **matplotlib pyplot** used to plot graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "#import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read flight data from csv file into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(616101, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df=pd.read_csv('all_flights.csv') # Read csv file into flight_df dataframe\n",
    "flight_df.shape                          # Display shape of array to see how many rows and columns are in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first 10 rows in the dataset to make sure data looks like it imported correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>CRS_ARR_TIME</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>N221WN</td>\n",
       "      <td>802</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>BWI</td>\n",
       "      <td>905</td>\n",
       "      <td>903.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1450</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>N8329B</td>\n",
       "      <td>3744</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>BWI</td>\n",
       "      <td>1500</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2045</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>N920WN</td>\n",
       "      <td>1019</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1800</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2045</td>\n",
       "      <td>2032.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>N480WN</td>\n",
       "      <td>1499</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>DAL</td>\n",
       "      <td>950</td>\n",
       "      <td>947.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1235</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>N227WN</td>\n",
       "      <td>3635</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1150</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1430</td>\n",
       "      <td>1423.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FL_DATE OP_UNIQUE_CARRIER TAIL_NUM  OP_CARRIER_FL_NUM ORIGIN DEST  \\\n",
       "0  2018-10-01                WN   N221WN                802    ABQ  BWI   \n",
       "1  2018-10-01                WN   N8329B               3744    ABQ  BWI   \n",
       "2  2018-10-01                WN   N920WN               1019    ABQ  DAL   \n",
       "3  2018-10-01                WN   N480WN               1499    ABQ  DAL   \n",
       "4  2018-10-01                WN   N227WN               3635    ABQ  DAL   \n",
       "\n",
       "   CRS_DEP_TIME  DEP_TIME  DEP_DELAY  CRS_ARR_TIME  ARR_TIME  ARR_DELAY  \\\n",
       "0           905     903.0       -2.0          1450    1433.0      -17.0   \n",
       "1          1500    1458.0       -2.0          2045    2020.0      -25.0   \n",
       "2          1800    1802.0        2.0          2045    2032.0      -13.0   \n",
       "3           950     947.0       -3.0          1235    1223.0      -12.0   \n",
       "4          1150    1151.0        1.0          1430    1423.0       -7.0   \n",
       "\n",
       "   CRS_ELAPSED_TIME  ACTUAL_ELAPSED_TIME  AIR_TIME  DISTANCE  Unnamed: 16  \n",
       "0             225.0                210.0     197.0    1670.0          NaN  \n",
       "1             225.0                202.0     191.0    1670.0          NaN  \n",
       "2             105.0                 90.0      80.0     580.0          NaN  \n",
       "3             105.0                 96.0      81.0     580.0          NaN  \n",
       "4             100.0                 92.0      80.0     580.0          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df.head()                         # Displays the top 10 rows from flight_df dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the names of the columns in the dataframe and their datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FL_DATE                 object\n",
       "OP_UNIQUE_CARRIER       object\n",
       "TAIL_NUM                object\n",
       "OP_CARRIER_FL_NUM        int64\n",
       "ORIGIN                  object\n",
       "DEST                    object\n",
       "CRS_DEP_TIME             int64\n",
       "DEP_TIME               float64\n",
       "DEP_DELAY              float64\n",
       "CRS_ARR_TIME             int64\n",
       "ARR_TIME               float64\n",
       "ARR_DELAY              float64\n",
       "CRS_ELAPSED_TIME       float64\n",
       "ACTUAL_ELAPSED_TIME    float64\n",
       "AIR_TIME               float64\n",
       "DISTANCE               float64\n",
       "Unnamed: 16            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df.dtypes  # Displays the names and data types of the columns in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataframe containing ONLY the columns we want to use as features and labels.\n",
    "This saves us spending time cleaning up data we are not using to train our model.\n",
    "This model will use OP_UNIQUE_CARRIER (the airline operating the flight) as a feature to predict the value of the label ARR_DELAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(616101, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe containing only OP_UNIQUE_CARRIER, DEP_DELAY, DISTANCE and ARR_DELAY\n",
    "min_flight_data_df = flight_df[['OP_UNIQUE_CARRIER','DEP_DELAY','DISTANCE','ARR_DELAY']] \n",
    "\n",
    "min_flight_data_df.shape                                          # Display the shape of the dataframe as a quick check to \n",
    "                                                                  # ensure dataframe has expected number of columns and rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of rows containing NaN/missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610334, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_missing_values_df = min_flight_data_df.dropna(axis=0,how='any')  # Use dropna to remove rows with NaN in any column\n",
    "no_missing_values_df.shape                                          # Display shape to see how many rows were removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does seem to be a relation between carrier and delay times. So maybe I can train a model using OP_UNIQUE_CARRIER as a feature.\n",
    "\n",
    "OP_UNIQUE_CARRIER is not numeric so I need to make it numeric, basically I want to know iif a flight is operated by a particular airline is it more likely to be late. \n",
    "\n",
    "I need to make a dummy column for each possible airline i.e. AIRCANADA 1/0 WESTJET 1/0 AIRTRANSAT 1/0 for every row. a value of 1 means the flight was operated by that carrier. Then I can include those columns as features when I train my model.\n",
    "\n",
    "The *[get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)* method in pandas will return a dataframe of dummy columns for a given column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         9E  AA  AS  B6  DL  EV  F9  G4  HA  MQ  NK  OH  OO  UA  WN  YV  YX\n",
       "0        0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "1        0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "2        0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "3        0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "4        0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "616096   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "616097   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "616098   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "616099   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "616100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "\n",
       "[610334 rows x 17 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df = pd.get_dummies(no_missing_values_df['OP_UNIQUE_CARRIER'])\n",
    "dummy_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one dataframe containing only the features. \n",
    "The OP_UNIQUE_CARRIER features are in the dummy dataframe\n",
    "The DEP_DELAY and DISTANCE features are in our no_missing_values_df\n",
    "\n",
    "We need to extract the DEP_DELAY and DISTANCE features into their own dataframe then combine the two dataframes into\n",
    "one single dataframe using teh pandas **concat** method\n",
    "\n",
    "Then we need to create one dataframe containing only the label (ARR_DELAY) \n",
    "If either of these has only one column you must reshape the dataframe to -1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataFrame containing the feature columns\n",
    "# combine the dummy dataframe with a dataframe containing the numeric features\n",
    "numeric_features = no_missing_values_df[['DISTANCE','DEP_DELAY']]\n",
    "all_features_df = pd.concat([dummy_df, numeric_features], axis=1)\n",
    "X = all_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing the labels\n",
    "# Reshape to -1,1 if only containing a single column\n",
    "y = no_missing_values_df['ARR_DELAY'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into two datasets, one for training the model, one for testing the model\n",
    "\n",
    "scikitlearn method [train_test_split]( \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) \n",
    "- **X** is the dataframe containing our features\n",
    "- **Y** is the dataframe containing our label\n",
    "- **test_size** determines what fraction of the data is put into the test dataframe\n",
    "- **random_state** defaults to a random number, by specifying a specific number I ensure the split I generate is reproducible. That way if I make changes I know changes in accuracy are not caused by different rows used as training or test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of your test and training datasets (i.e. how many rows in each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427233, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183101, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using scikitlearn [LinearRegression]( \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "\n",
    "Your feature must be numeric that's why we created the dummy columns for OP_UNIQUE_CARRIER\n",
    "\n",
    "Your training data cannot contain any missing values in rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()     # Create a scikit learn LinearRegression object\n",
    "regressor.fit(X_train, y_train)    # Use the fit methong to train the model using your training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what arrival delays are predicted for our test data by using the **predict** method of our linearRegression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the actual arrival delay times and the predicted arrival delay times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         Actual  Predicted\n",
       "0        -13.0 -12.181343\n",
       "1        -24.0  -4.946919\n",
       "2        100.0  65.085465\n",
       "3         -8.0  -8.693103\n",
       "4        -19.0 -13.748650\n",
       "...        ...        ...\n",
       "183096    48.0  57.503282\n",
       "183097   -24.0  -7.836193\n",
       "183098    20.0  23.317080\n",
       "183099    47.0  47.702381\n",
       "183100   -11.0  -5.158120\n",
       "\n",
       "[183101 rows x 2 columns]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine the two 1D numpy arrays into a 2D array\n",
    "combined = np.hstack((y_test,y_pred))\n",
    "#Convert to a DataFrame\n",
    "accuracy_df = pd.DataFrame(combined,columns=['Actual','Predicted'])\n",
    "accuracy_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do some calculations to get a sense of overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error:  8.909834662395848\n"
     ]
    }
   ],
   "source": [
    "print('Mean absolute error: ',metrics.mean_absolute_error(y_test,y_pred))\n",
    "# For comparison, when we trained with only DEP_DELAY as a feature we get \n",
    "# Mean absolute error:  9.033505526602951\n",
    "# For comparison, when we trained with DEP_DELAY and DISTANCE as a feature we get\n",
    "# Mean absolute error:  9.01393034185557"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 158.60062293292938\n"
     ]
    }
   ],
   "source": [
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test,y_pred))\n",
    "# For comparison, when we trained with only DEP_DELAY as a feature we get \n",
    "# Mean Squared Error: 163.26825261343365\n",
    "# For comparison, when we trained with DEP_DELAY and DISTANCE as a feature we get\n",
    "# Mean Squared Error: 162.04368013600566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 12.593673925147076\n"
     ]
    }
   ],
   "source": [
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "# For comparison, when we trained with only DEP_DELAY as a feature we get \n",
    "# Mean Squared Error: 163.26825261343365\n",
    "# For comparison, when we trained with DEP_DELAY and DISTANCE as a feature we get\n",
    "# Root Mean Squared Error: 12.729637863506003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check coefficients for our attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.40729462e+00  6.00823198e-01  2.23344031e+00  6.87136382e-01\n",
      "  -2.97148497e+00  1.82041345e+00 -4.73946776e-01 -6.07887942e-01\n",
      "   2.68212490e+00  4.77563583e-01 -2.01527514e+00 -2.71641224e+00\n",
      "  -3.44648343e-02  1.48651590e+00 -2.69327792e+00  2.58568164e+00\n",
      "   3.46345075e-01 -2.19044789e-03  1.00478987e+00]]\n",
      "Index(['9E', 'AA', 'AS', 'B6', 'DL', 'EV', 'F9', 'G4', 'HA', 'MQ', 'NK', 'OH',\n",
      "       'OO', 'UA', 'WN', 'YV', 'YX', 'DISTANCE', 'DEP_DELAY'],\n",
      "      dtype='object')\n",
      "9E: -1.40729462239299\n",
      "AA: 0.6008231984182523\n",
      "AS: 2.2334403146835338\n",
      "B6: 0.6871363823660214\n",
      "DL: -2.9714849674095416\n",
      "EV: 1.8204134458169159\n",
      "F9: -0.4739467762156722\n",
      "G4: -0.6078879416830151\n",
      "HA: 2.6821248991647404\n",
      "MQ: 0.4775635827815127\n",
      "NK: -2.015275136285377\n",
      "OH: -2.716412239581445\n",
      "OO: -0.034464834340939325\n",
      "UA: 1.486515901010831\n",
      "WN: -2.693277919884317\n",
      "YV: 2.585681638316784\n",
      "YX: 0.3463450752357463\n",
      "DISTANCE: -0.0021904478861746695\n",
      "DEP_DELAY: 1.0047898718148953\n"
     ]
    }
   ],
   "source": [
    "print(regressor.coef_)\n",
    "print(X_train.columns)\n",
    "\n",
    "# Loop through to display these in a more readable way\n",
    "for index in range(len(X_train.columns)):\n",
    "    print (str(X_train.columns[index]) + ': ' + str(regressor.coef_[0,index])  )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we combine multiple features we start to see changes in the coefficients across airlines. \n",
    "- DEP_DELAY still shows a high coefficient and is a large determinign factor for ARR_DELAY\n",
    "- The values for OP_UNIQUE_CARRIER are larger than the values for DISTANCE, so it seems the carrier is a bigger influence in predciting arrival delay than distance\n",
    "\n",
    "- Delta flights (DL) seem less likely to be late since they have a larger negative value\n",
    "- Mesa airlines (YV) seems more likely to be late since they have a larger positive value \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
